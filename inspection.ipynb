{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sec_1 = pd.read_csv(join(\"./data/accelerometer_data_section_1.csv\"))\n",
    "data_sec_2 = pd.read_csv(join(\"./data/accelerometer_data_section_2.csv\"))\n",
    "data_sec_3 = pd.read_csv(join(\"./data/accelerometer_data_section_3.csv\"))\n",
    "data_sec_4 = pd.read_csv(join(\"./data/accelerometer_data_section_4.csv\"))\n",
    "data_sec_5 = pd.read_csv(join(\"./data/accelerometer_data_section_5.csv\"))\n",
    "data_sec_6 = pd.read_csv(join(\"./data/accelerometer_data_section_6.csv\"))\n",
    "data_sec_7 = pd.read_csv(join(\"./data/accelerometer_data_section_7.csv\"))\n",
    "\n",
    "vehicle_timestamps = pd.read_csv(join(\"./data/vehicle_timestamps.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to Datetimes in new columns\n",
    "data_sec_1['Timestamp'] = pd.to_datetime(data_sec_1['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_2['Timestamp'] = pd.to_datetime(data_sec_2['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_3['Timestamp'] = pd.to_datetime(data_sec_3['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_4['Timestamp'] = pd.to_datetime(data_sec_4['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_5['Timestamp'] = pd.to_datetime(data_sec_5['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_6['Timestamp'] = pd.to_datetime(data_sec_6['Timestamp'], infer_datetime_format=True)\n",
    "data_sec_7['Timestamp'] = pd.to_datetime(data_sec_7['Timestamp'], infer_datetime_format=True)\n",
    "\n",
    "\n",
    "vehicle_timestamps['Timestamp'] = pd.to_datetime(vehicle_timestamps['Timestamp'], infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_sec_1.append([data_sec_2,data_sec_3,data_sec_4,data_sec_5,data_sec_6,data_sec_7])\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encode direction:\n",
    "vehicle_timestamps = pd.get_dummies(vehicle_timestamps, columns=['Direction'])\n",
    "# print(vehicle_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clifton_timestamps = vehicle_timestamps[vehicle_timestamps['Direction_Clifton'] == 1]\n",
    "# print(clifton_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leigh_woods_timestamps = vehicle_timestamps[vehicle_timestamps['Direction_Leigh_Woods'] == 1]\n",
    "# print(leigh_woods_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_timestamps_group = vehicle_timestamps.groupby('Timestamp').agg({\n",
    "#     'Direction': '<br>'.join,\n",
    "#     'Timestamp':'sum'\n",
    "# })\n",
    "\n",
    "# data_group = data.groupby('Timestamp').agg({\n",
    "#     'Acceleration': '<br>'.join,\n",
    "#     'Timestamp':'sum'\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_index = pd.date_range(data['Timestamp'].min(), data['Timestamp'].max())\n",
    "# # print(time_index)\n",
    "\n",
    "# vehicle_timestamps_hourly = pd.DataFrame(vehicle_timestamps['Direction'])\n",
    "# vehicle_timestamps_hourly = vehicle_timestamps_hourly.reindex(time_index, fill_value=np.nan)\n",
    "# vehicle_timestamps_hourly = vehicle_timestamps_hourly.fillna(method='ffill')\n",
    "\n",
    "# # df_monthly = \\\n",
    "# # pd.DataFrame(data['Timestamp'].resample(rule='1M').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate dataset\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date').head(100)\n",
    "df = pd.read_csv('datasets/a10_missings.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "fig, axes = plt.subplots(7, 1, sharex=True, figsize=(10, 12))\n",
    "plt.rcParams.update({'xtick.bottom' : False})\n",
    "\n",
    "## 1. Actual -------------------------------\n",
    "df_orig.plot(title='Actual', ax=axes[0], label='Actual', color='red', style=\".-\")\n",
    "df.plot(title='Actual', ax=axes[0], label='Actual', color='green', style=\".-\")\n",
    "axes[0].legend([\"Missing Data\", \"Available Data\"])\n",
    "\n",
    "## 2. Forward Fill --------------------------\n",
    "df_ffill = df.ffill()\n",
    "error = np.round(mean_squared_error(df_orig['value'], df_ffill['value']), 2)\n",
    "df_ffill['value'].plot(title='Forward Fill (MSE: ' + str(error) +\")\", ax=axes[1], label='Forward Fill', style=\".-\")\n",
    "\n",
    "## 3. Backward Fill -------------------------\n",
    "df_bfill = df.bfill()\n",
    "error = np.round(mean_squared_error(df_orig['value'], df_bfill['value']), 2)\n",
    "df_bfill['value'].plot(title=\"Backward Fill (MSE: \" + str(error) +\")\", ax=axes[2], label='Back Fill', color='firebrick', style=\".-\")\n",
    "\n",
    "## 4. Linear Interpolation ------------------\n",
    "df['rownum'] = np.arange(df.shape[0])\n",
    "df_nona = df.dropna(subset = ['value'])\n",
    "f = interp1d(df_nona['rownum'], df_nona['value'])\n",
    "df['linear_fill'] = f(df['rownum'])\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['linear_fill']), 2)\n",
    "df['linear_fill'].plot(title=\"Linear Fill (MSE: \" + str(error) +\")\", ax=axes[3], label='Cubic Fill', color='brown', style=\".-\")\n",
    "\n",
    "## 5. Cubic Interpolation --------------------\n",
    "f2 = interp1d(df_nona['rownum'], df_nona['value'], kind='cubic')\n",
    "df['cubic_fill'] = f2(df['rownum'])\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['cubic_fill']), 2)\n",
    "df['cubic_fill'].plot(title=\"Cubic Fill (MSE: \" + str(error) +\")\", ax=axes[4], label='Cubic Fill', color='red', style=\".-\")\n",
    "\n",
    "# Interpolation References:\n",
    "# https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
    "# https://docs.scipy.org/doc/scipy/reference/interpolate.html\n",
    "\n",
    "## 6. Mean of 'n' Nearest Past Neighbors ------\n",
    "def knn_mean(ts, n):\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            n_by_2 = np.ceil(n/2)\n",
    "            lower = np.max([0, int(i-n_by_2)])\n",
    "            upper = np.min([len(ts)+1, int(i+n_by_2)])\n",
    "            ts_near = np.concatenate([ts[lower:i], ts[i:upper]])\n",
    "            out[i] = np.nanmean(ts_near)\n",
    "    return out\n",
    "\n",
    "df['knn_mean'] = knn_mean(df.value.values, 8)\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['knn_mean']), 2)\n",
    "df['knn_mean'].plot(title=\"KNN Mean (MSE: \" + str(error) +\")\", ax=axes[5], label='KNN Mean', color='tomato', alpha=0.5, style=\".-\")\n",
    "\n",
    "## 7. Seasonal Mean ----------------------------\n",
    "def seasonal_mean(ts, n, lr=0.7):\n",
    "    \"\"\"\n",
    "    Compute the mean of corresponding seasonal periods\n",
    "    ts: 1D array-like of the time series\n",
    "    n: Seasonal window length of the time series\n",
    "    \"\"\"\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            ts_seas = ts[i-1::-n]  # previous seasons only\n",
    "            if np.isnan(np.nanmean(ts_seas)):\n",
    "                ts_seas = np.concatenate([ts[i-1::-n], ts[i::n]])  # previous and forward\n",
    "            out[i] = np.nanmean(ts_seas) * lr\n",
    "    return out\n",
    "\n",
    "df['seasonal_mean'] = seasonal_mean(df.value, n=12, lr=1.25)\n",
    "error = np.round(mean_squared_error(df_orig['value'], df['seasonal_mean']), 2)\n",
    "df['seasonal_mean'].plot(title=\"Seasonal Mean (MSE: \" + str(error) +\")\", ax=axes[6], label='Seasonal Mean', color='blue', alpha=0.5, style=\".-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x = data['Timestamp'],\n",
    "                         y = data['Acceleration'],\n",
    "                         mode='lines',\n",
    "                         \n",
    "                         name='Acceleration'))  \n",
    "\n",
    "fig.add_trace(go.Scatter(x = clifton_timestamps['Timestamp'],\n",
    "                         y = clifton_timestamps['Direction_Leigh_Woods'],\n",
    "                         mode='markers',\n",
    "                         \n",
    "                         name='Clifton Direction'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x = leigh_woods_timestamps['Timestamp'],\n",
    "                         y = leigh_woods_timestamps['Direction_Clifton'],\n",
    "                         mode='markers',\n",
    "                        \n",
    "                         name='Leigh Woods Direction'))    \n",
    "\n",
    "fig.update_xaxes(range=[clifton_timestamps['Timestamp'].min(), clifton_timestamps['Timestamp'].max()])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot subplot data\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=7, cols=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_1['Timestamp'],\n",
    "    y = data_sec_1['Acceleration'],\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_2['Timestamp'],\n",
    "    y = data_sec_2['Acceleration'],\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_3['Timestamp'],\n",
    "    y = data_sec_3['Acceleration'],\n",
    "), row=3, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_4['Timestamp'],\n",
    "    y = data_sec_4['Acceleration'],\n",
    "), row=4, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_5['Timestamp'],\n",
    "    y = data_sec_5['Acceleration'],\n",
    "), row=5, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_6['Timestamp'],\n",
    "    y = data_sec_6['Acceleration'],\n",
    "), row=6, col=1)\n",
    "\n",
    "fig.append_trace(go.Scatter(\n",
    "    x = data_sec_7['Timestamp'],\n",
    "    y = data_sec_7['Acceleration'],\n",
    "), row=7, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1080, width=1920, title_text=\"Stacked Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
